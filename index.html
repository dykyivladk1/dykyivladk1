<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NYX Model</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap');

        body {
            font-family: 'Roboto', sans-serif;
            margin: 0;
            padding: 40px;
            background-color: #1b1f24;
            color: #dcdcdc;
            line-height: 1.8;
        }

        h1 {
            font-size: 3.5em;
            color: #ffffff;
            border-bottom: 4px solid #4dabf7;
            padding-bottom: 10px;
            margin-bottom: 25px;
            font-weight: 700;
        }

        h2 {
            font-size: 2.5em;
            color: #ffffff;
            border-bottom: 3px solid #4dabf7;
            padding-bottom: 8px;
            margin-top: 35px;
            margin-bottom: 20px;
            font-weight: 500;
        }

        p {
            margin-bottom: 25px;
            color: #c9c9c9;
            font-weight: 300;
        }

        ul, ol {
            margin: 0 0 20px 20px;
            color: #c9c9c9;
            font-weight: 300;
        }

        code {
            background-color: #2b2d31;
            color: #ffb84d;
            padding: 4px 6px;
            border-radius: 4px;
            font-size: 1em;
        }

        pre {
            background-color: #2b2d31;
            color: #ffb84d;
            padding: 15px;
            border-radius: 4px;
            overflow-x: auto;
            font-size: 1em;
            margin-bottom: 20px;
        }

        a {
            color: #4dabf7;
            text-decoration: none;
            border-bottom: 1px solid #4dabf7;
        }

        a:hover {
            color: #6cc1ff;
            border-bottom-color: #6cc1ff;
        }

        .release-date {
            text-align: center;
            font-size: 3em;
            font-weight: 700;
            margin: 40px 0;
            color: #ff6b6b;
        }

        .footer {
            text-align: center;
            margin-top: 50px;
            padding-top: 15px;
            font-size: 0.9em;
            color: #888888;
        }
    </style>
</head>

<body>
    <h1>NYX Model</h1>
    <div class="release-date">
        <strong>20 September</strong>
    </div>
    <p>The <strong>NYX</strong> model is currently in the training stage and will be available for testing on the above date. This generative Transformer-based model is designed for autoregressive natural language generation tasks, capable of generating text and incorporating advanced techniques for efficient and scalable training.</p>

    <h2>Model Overview</h2>
    <p>The NYX model features the following characteristics:</p>
    <ul>
        <li><strong>Model Parameters</strong>: 30,020,096 total trainable parameters.</li>
        <li><strong>Architecture</strong>: 2 Transformer layers with multi-head self-attention, feedforward networks, and residual connections.</li>
        <li><strong>Positional Encoding</strong>: Rotary embeddings with XPOS scaling.</li>
        <li><strong>Low-Rank Fine-Tuning</strong>: Supports LoRA modules.</li>
        <li><strong>Regularization</strong>: Dropout layers in both attention and feedforward components.</li>
    </ul>

    <h2>Features</h2>
    <ul>
        <li><strong>Parameter Efficiency</strong>: High performance with 30M parameters.</li>
        <li><strong>Rotary Embeddings</strong>: Enhanced positional encoding for better generalization.</li>
        <li><strong>LoRA Fine-Tuning</strong>: Reduces training cost while maintaining performance.</li>
        <li><strong>Causal Masking</strong>: For autoregressive modeling.</li>
    </ul>

    <h2>Model Architecture</h2>
    <p>The NYX model consists of the following components:</p>
    <ol>
        <li><strong>Embedding Layer</strong>: Maps input tokens to a 128-dimensional space.</li>
        <li><strong>Transformer Layers</strong>: 2 layers with multi-head attention (4 heads, 32-dimensional each) and feedforward networks.</li>
        <li><strong>Output Layer</strong>: Projects hidden states back to the vocabulary size.</li>
    </ol>

    <h2>Installation</h2>
    <p>Ensure you have the following dependencies:</p>
    <ul>
        <li>Python 3.8+</li>
        <li>PyTorch 1.8+</li>
        <li>Transformer library (for tokenization)</li>
        <li>Beartype (for type checking)</li>
        <li>Einops (for tensor operations)</li>
        <li>Accelerate (for distributed training)</li>
    </ul>
    <p>To install these packages, run:</p>
    <pre><code>pip install -r requirements.txt</code></pre>

    <h2>Testing</h2>
    <p>To test the model:</p>
    <ol>
        <li>Install trained weights here: <a href="[link]">Download Weights</a>.</li>
        <li>Move the weights to a folder <code>./weights</code>.</li>
        <li>Run the following command:</li>
    </ol>
    <pre><code>python testing.py --prompt &lt;PROMPT TEXT&gt; --max_seq_len &lt;MAX SEQUENCE LEN&gt;</code></pre>

    <div class="footer">
        <p>&copy; 2024 NYX Model Team. All rights reserved.</p>
    </div>
</body>

</html>
